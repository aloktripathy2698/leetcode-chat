# LeetCode Assistant

Productivity assistant for LeetCode that lives directly inside the browser. A Chrome extension observes the active problem, syncs structured context to a FastAPI backend, runs retrieval-augmented generation (RAG) with vector search + LLMs, and returns curated guidance in a side panel chat.

---

## âœ¨ Features

- **In-browser coaching** â€“ context-aware chat panel that understands the LeetCode problem you currently have open.
- **Automatic problem scraping** â€“ DOM + GraphQL scrapers populate description, constraints, and examples with millisecond latency.
- **RAG pipeline** â€“ LangGraph orchestrates pgvector similarity search, Redis caching, and an LLM prompt that returns JSON summaries.
- **Streaming answers + syntax highlighting** â€“ responses arrive token-by-token and render rich Markdown with Prism-powered code blocks.
- **Theme toggle built in** â€“ switch between light and dark modes on the fly; the extension remembers your preference.
- **Modular monorepo** â€“ separate `apps/extension` and `apps/api` packages with shared types and reproducible builds.
- **Developer tooling** â€“ Docker Compose stack, hot-reload Uvicorn server, npm proxy scripts, and detailed setup docs.

---

## ğŸ§± Architecture

```
â”œâ”€â”€ apps
â”‚   â”œâ”€â”€ api
â”‚   â”‚   â”œâ”€â”€ app
â”‚   â”‚   â”‚   â”œâ”€â”€ api         # FastAPI routers
â”‚   â”‚   â”‚   â”œâ”€â”€ core        # Settings & logging
â”‚   â”‚   â”‚   â”œâ”€â”€ db          # SQLAlchemy engine + pgvector models
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas     # Pydantic request/response models
â”‚   â”‚   â”‚   â””â”€â”€ services    # RAG pipeline, caching, embeddings
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ .env.example
â”‚   â””â”€â”€ extension
â”‚       â”œâ”€â”€ public
â”‚       â”œâ”€â”€ src             # React/Tailwind Chrome extension source
â”‚       â”œâ”€â”€ dist            # Built assets (generated)
â”‚       â”œâ”€â”€ package.json
â”‚       â””â”€â”€ vite.config.ts
â”œâ”€â”€ infra
â”‚   â””â”€â”€ docker
â”‚       â””â”€â”€ docker-compose.yml
â””â”€â”€ package.json            # Root scripts (proxy to extension workspace)
```

---

## ğŸ”‘ Tech Stack

- **Frontend:** React 18, TypeScript, Vite, Tailwind CSS, Chrome Extension APIs
- **Backend:** FastAPI, AsyncIO, Pydantic, LangChain, LangGraph, OpenAI API
- **Data Layer:** PostgreSQL 16 (`pgvector`), Redis 7, SQLAlchemy 2.x
- **Infrastructure:** Docker, Docker Compose, uvicorn/gunicorn

---

## ğŸš€ Quick Start

### 1. Prerequisites

- Node.js 18+
- Docker Desktop (or Docker Engine) + Docker Compose V2
- An OpenAI API key (for both chat + embeddings)

### 2. Clone and install

```bash
git clone https://github.com/<you>/leetcode-assistant.git
cd leetcode-assistant

# Install extension dependencies
npm install --prefix apps/extension
```

### 3. Configure the backend

```bash
cp apps/api/.env.example apps/api/.env
# edit apps/api/.env and set:
# OPENAI_API_KEY=sk-your-secret-key
```

### 4. Run backend services

```bash
docker compose -f infra/docker/docker-compose.yml up -d --build
curl http://localhost:8000/api/v1/health   # â†’ {"status":"healthy"}
```

Services exposed locally:

| Service   | Port | Notes                      |
|-----------|------|----------------------------|
| FastAPI   | 8000 | REST API & docs at `/docs` |
| Postgres  | 5432 | Includes pgvector          |
| Redis     | 6379 | Used for response caching  |

### 5. Build and load the Chrome extension

```bash
npm run build --prefix apps/extension
```

- Open Chrome â†’ `chrome://extensions`
- Enable **Developer mode**
- Click **Load unpacked** and choose `apps/extension/dist/`
- Open the extensionâ€™s **Settings** page, confirm the API base URL (`http://localhost:8000/api/v1`), click **Save** and **Test connection**
- Navigate to any LeetCode problem and open the *LeetCode Assistant* side panel

---

## ğŸ› ï¸ Development Scripts

From repository root:

| Command | Action |
|---------|--------|
| `npm run dev` | Start the Vite dev server for the extension (`apps/extension`) |
| `npm run build` | Type-check + production build of the extension |
| `npm run lint` | ESLint for the extension codebase |
| `python3 -m compileall apps/api/app` | Quick syntax check for backend modules |

Backend container uses live-reload via Uvicorn when `/app/app` changes.

### Tests

- **Backend:** `pytest apps/api/tests`  
- **Extension:** build + lint (no unit tests yet)

### Continuous Integration

GitHub Actions (`.github/workflows/ci.yml`) runs on every push/PR to `main`. The workflow builds the FastAPI service (pip install + `python -m compileall`) and verifies the Chrome extension (`npm ci`, lint, and build). Keep new dependencies declared in `apps/api/requirements.txt` or `apps/extension/package.json` so the pipeline succeeds.

---

## ğŸ§  RAG Pipeline Overview

1. **Problem ingestion** â€“ extension posts the scraped problem to `/api/v1/documents`.  
2. **Embedding + storage** â€“ FastAPI service chunkifies content, obtains embeddings, and writes vectors to PostgreSQL (`pgvector`).  
3. **Retrieval** â€“ when a chat question arrives, LangGraph queries pgvector for top-k chunks, enriched with metadata.  
4. **LLM response** â€“ LangChain `ChatOpenAI` consumes a structured prompt and returns JSON containing `answer` + `summary`.  
5. **Caching** â€“ Redis stores chat responses keyed by slug + normalized conversation history to avoid repeated LLM calls.

---

## ğŸ§ª API Reference

- `GET /api/v1/health` â€“ readiness probe
- `GET /api/v1/docs` â€“ Swagger UI
- `POST /api/v1/documents` â€“ ingest problem context (handled by extension)
- `POST /api/v1/chat` â€“ accepts `question`, `problem`, and `history`, returns answer + summary + source snippets

---

## ğŸ›¡ï¸ Troubleshooting

| Symptom | Fix |
|---------|-----|
| Extension shows â€œBackend unreachableâ€ | Ensure Docker stack is running and API URL is `http://localhost:8000/api/v1`; click **Test connection** in Settings. |
| â€œContext sync failedâ€ | The `/documents` endpoint rejected the request. Check logs (`docker compose â€¦ logs api`) for authentication or schema errors. |
| â€œFailed to fetchâ€ after sending a chat | Inspect API logs for 500 errors (often due to invalid JSON shape or missing API key). |
| Permission denied to Docker socket | On macOS, grant Terminal/CLI access to Docker Desktop or rerun with elevated privileges. |

---

## ğŸ—ºï¸ Roadmap Ideas

- Streaming responses for richer UX
- Persistent user chat history
- Multi-user authentication / rate limiting
- LangSmith or OpenTelemetry tracing for prompt evaluation
- Gemini or other provider fallbacks

---

With the backend running and the extension loaded, open any LeetCode problem and launch the side panelâ€”LeetCode Assistant will ingest the context, surface relevant snippets, and deliver actionable guidance tailored to your question. Happy grinding! ğŸ™Œ
